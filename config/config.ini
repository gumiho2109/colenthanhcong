[dataset]
tokenizer=facebook/bart-base
batch_size=4
max_length=512
train_path=./data/train.json
shuffle=True
test_path=./data/test.json
valid_path=./data/val.json

[model]
name=bart-sum
pre_trained_name=facebook/bart-base
sent_rep_tokens=True
pooler_dropout=0.2
dropout_prop=0.1
nhead=8
ffn_dim=2048
num_layers=2
n_classes=1

[trainer]
epochs=10
losses=BCELoss,CrossEntropyLoss
n_losses=2
accumulation_steps=8
n_training_steps=0
n_warmup_steps=0
checkpoint=./checkpoint/
delta=1.0e-5
eval_steps=50
log=./log/
lr=3e-4
no_decay=bias,LayerNorm.weight
num_freeze_layers=4
patience=5
warmup_prop=0.01
weight_decay=0.015